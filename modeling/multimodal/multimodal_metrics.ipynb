{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1f349c-7311-4f02-83b8-6237de2b971c",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ab2e87b-d14f-4909-ad18-378d8fbabede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\compute\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.distributions as dist\n",
    "from torchsummary import summary\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import re\n",
    "from skimage.metrics  import structural_similarity as ssim\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "from importlib import reload\n",
    "import visualization\n",
    "\n",
    "# locals\n",
    "import model_architectures\n",
    "\n",
    "reload(model_architectures)\n",
    "from model_architectures import VAE, Data3D\n",
    "\n",
    "reload(visualization)\n",
    "from visualization import brain_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191b1f59-9cf8-41a6-b761-ae45d53a3e5e",
   "metadata": {},
   "source": [
    "### Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edfb2ece-3cdc-43a0-a70f-25797ea71f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_dir = r\"D:/school/research\"\n",
    "code_dir = os.path.join(research_dir, \"code\")\n",
    "p2_dir = os.path.join(code_dir, \"paper_two_code\")\n",
    "model_dir = os.path.join(p2_dir, \"models\")\n",
    "metrics_dir = os.path.join(p2_dir, \"metrics\")\n",
    "mmmetrics_dir = os.path.join(metrics_dir, \"multimodal\")\n",
    "data_dir = os.path.join(research_dir, \"data\")\n",
    "dhcp_rel2 = os.path.join(data_dir, \"dhcp_rel2\")\n",
    "processed_dir = os.path.join(dhcp_rel2, \"processed\")\n",
    "volume_dir = os.path.join(processed_dir, \"volumes\")\n",
    "l1_dir = os.path.join(volume_dir, \"l1\")\n",
    "l5_dir = os.path.join(volume_dir, \"l5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb33a806-d10f-4d0e-a814-d31680e5c36b",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af6cf54-ccb5-42f3-aa58-0ddf9b380eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "num_samples = int(len(os.listdir(l1_dir)) / 2)\n",
    "samples = np.array([i for i in range(0, num_samples)])\n",
    "np.random.shuffle(samples)\n",
    "\n",
    "split_val = int(0.8 * num_samples)\n",
    "train_indices = samples[0:split_val]\n",
    "val_indices = samples[split_val:]\n",
    "\n",
    "num_test = int(len(os.listdir(l5_dir)) / 2)\n",
    "test_indices = np.array([i for i in range(0, num_test)])\n",
    "\n",
    "train = Data3D(l1_dir, train_indices, t2_only=False)\n",
    "val = Data3D(l1_dir, val_indices, t2_only=False)\n",
    "test = Data3D(l5_dir, test_indices, t2_only=False)\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train, batch_size=batch_size)#, num_workers=1)\n",
    "val_loader = DataLoader(val, batch_size=batch_size)#, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16b5d07-40d3-4d63-82b9-803df8ff6a2c",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bace3c20-db2d-4b8e-8e26-80d85e5efabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_bands = [\n",
    "    {\n",
    "        \"range\": \"-inf to -4\",\n",
    "        \"low\": -np.inf,\n",
    "        \"high\": -4\n",
    "    },\n",
    "    {\n",
    "        \"range\": \"-4 to -3\",\n",
    "        \"low\": -4,\n",
    "        \"high\": -3\n",
    "    },\n",
    "    {\n",
    "        \"range\": \"-3 to -2\",\n",
    "        \"low\": -3,\n",
    "        \"high\": -2\n",
    "    },\n",
    "    {\n",
    "        \"range\": \"2 to 3\",\n",
    "        \"low\": 2,\n",
    "        \"high\": 3\n",
    "    },\n",
    "    {\n",
    "        \"range\": \"3 to 4\",\n",
    "        \"low\": 3,\n",
    "        \"high\": 4\n",
    "    },\n",
    "    {\n",
    "        \"range\": \"4 to inf\",\n",
    "        \"low\": 4,\n",
    "        \"high\": np.inf\n",
    "    }\n",
    "]\n",
    "\n",
    "def connected_components_2d(diff):\n",
    "    _, labels = cv2.connectedComponents(diff)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "def calculate_clusters(diff, threshold=2):\n",
    "    cluster_diff = diff.copy()\n",
    "    filter_mask = (diff > -threshold) & (diff < threshold)\n",
    "    cluster_diff[filter_mask] = 0\n",
    "    cluster_diff[cluster_diff != 0] = 1\n",
    "    prepared_diff = cluster_diff.astype('uint8')\n",
    "    sizes = []\n",
    "    \n",
    "    for idx in range(0, 256):\n",
    "        clusters = connected_components_2d(prepared_diff[:,:,idx])\n",
    "        values, counts = np.unique(clusters, return_counts=True)\n",
    "        sizes.extend(counts[1:])\n",
    "        \n",
    "    return sizes\n",
    "\n",
    "def get_overall_metrics(model, data):\n",
    "    criterion = nn.MSELoss()\n",
    "    losses = []\n",
    "    clusters = []\n",
    "    banded_metrics = {}\n",
    "    for band in std_bands:\n",
    "        banded_metrics[f\"{band['range']} pixels\"] = []\n",
    "        banded_metrics[f\"{band['range']} clusters\"] = []\n",
    "\n",
    "    for sample in data:\n",
    "        x = torch.Tensor(sample).reshape((1,) + sample.shape).cuda()\n",
    "        pred = model(x)\n",
    "        \n",
    "        losses.append(float(criterion(x, pred).cpu()))\n",
    "        \n",
    "        og = sample\n",
    "        pred = pred.reshape(og.shape).detach().cpu().numpy()\n",
    "        \n",
    "        diff = np.sum(og, axis=0) - np.sum(pred, axis=0)\n",
    "        diff_norm = diff / 0.1\n",
    "        \n",
    "        clusters.append(calculate_clusters(diff_norm))\n",
    "        \n",
    "        for band in std_bands:\n",
    "            filter_mask = (diff_norm > band[\"low\"]) & (diff_norm < band[\"high\"])\n",
    "            banded_diff = diff_norm.copy()\n",
    "            banded_diff[np.invert(filter_mask)] = 0\n",
    "            banded_diff[banded_diff != 0] = 1\n",
    "            banded_diff = banded_diff.astype('uint8')\n",
    "            \n",
    "            banded_metrics[f\"{band['range']} pixels\"].append(np.sum(banded_diff))\n",
    "            \n",
    "            sizes = []\n",
    "            for idx in range(0, 256):\n",
    "                cc = connected_components_2d(banded_diff[:,:,idx])\n",
    "                values, counts = np.unique(cc, return_counts=True)\n",
    "                sizes.extend(counts[1:])\n",
    "            banded_metrics[f\"{band['range']} clusters\"].append(sizes)\n",
    "\n",
    "    return losses, clusters, banded_metrics\n",
    "\n",
    "def save_values(loss, cluster, bands, name):\n",
    "    np.save(os.path.join(mmmetrics_dir, f\"{name}_losses.npy\"), loss)\n",
    "    np.save(os.path.join(mmmetrics_dir, f\"{name}_clusters.npy\"), cluster)\n",
    "    with open(os.path.join(mmmetrics_dir, f\"{name}_banded_metrics.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(bands,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b09e81e-bae3-4319-9015-077b52e59919",
   "metadata": {},
   "source": [
    "### Get Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3e12d488-0e88-4fff-9d86-2879f95e7e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1_t2\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\compute\\envs\\torch\\lib\\site-packages\\numpy\\lib\\npyio.py:501: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "test\n",
      "t2\n",
      "train\n",
      "val\n",
      "test\n",
      "t1\n",
      "train\n",
      "val\n",
      "test\n",
      "CPU times: total: 11h 56min 43s\n",
      "Wall time: 53min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_harness = [\n",
    "    {\n",
    "        \"info\": \"t1_t2\",\n",
    "        \"model_name\": \"vae_rel2_t1_t2_second_session.pt\",\n",
    "        \"t1_only\": False,\n",
    "        \"t2_only\": False,\n",
    "        \"model\": VAE(2)\n",
    "    },\n",
    "    {\n",
    "        \"info\": \"t2\",\n",
    "        \"model_name\": \"vae_rel2_t2_second_session.pt\",\n",
    "        \"t1_only\": False,\n",
    "        \"t2_only\": True,\n",
    "        \"model\": VAE(1)\n",
    "    },\n",
    "    {\n",
    "        \"info\": \"t1\",\n",
    "        \"model_name\": \"vae_rel2_t1_second_session.pt\",\n",
    "        \"t1_only\": True,\n",
    "        \"t2_only\": False,\n",
    "        \"model\": VAE(1)\n",
    "    }\n",
    "]\n",
    "\n",
    "for model_info in model_harness:\n",
    "    print(model_info[\"info\"])\n",
    "    # Define data\n",
    "    train = Data3D(l1_dir, train_indices, t1_only=model_info[\"t1_only\"], t2_only=model_info[\"t2_only\"])\n",
    "    val = Data3D(l1_dir, val_indices, t1_only=model_info[\"t1_only\"], t2_only=model_info[\"t2_only\"])\n",
    "    test = Data3D(l5_dir, test_indices, t1_only=model_info[\"t1_only\"], t2_only=model_info[\"t2_only\"])\n",
    "\n",
    "    # Define model\n",
    "    model = model_info[\"model\"]\n",
    "    model_path = os.path.join(model_dir, model_info[\"model_name\"])\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"train\")\n",
    "    train_losses, train_clusters, train_bands = get_overall_metrics(model, train)\n",
    "    save_values(train_losses, train_clusters, train_bands, f\"{model_info['info']}_train\")\n",
    "    \n",
    "    print(\"val\")\n",
    "    val_losses, val_clusters, val_bands = get_overall_metrics(model, val)\n",
    "    save_values(val_losses, val_clusters, val_bands, f\"{model_info['info']}_val\")\n",
    "    \n",
    "    print(\"test\")\n",
    "    test_losses, test_clusters, test_bands = get_overall_metrics(model, test)\n",
    "    save_values(test_losses, test_clusters, test_bands, f\"{model_info['info']}_test\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2f992-16d3-4cc6-9aed-59ec9581bb3c",
   "metadata": {},
   "source": [
    "### Get Split Metrics for Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2e9ed406-ed09-4243-924f-c59414ad3e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multimodal_metrics(model, data):\n",
    "    criterion = nn.MSELoss()\n",
    "    t1_losses = []\n",
    "    t2_losses = []\n",
    "    t1_clusters = []\n",
    "    t2_clusters = []\n",
    "    t1_banded_metrics = {}\n",
    "    for band in std_bands:\n",
    "        t1_banded_metrics[f\"{band['range']} pixels\"] = []\n",
    "        t1_banded_metrics[f\"{band['range']} clusters\"] = []\n",
    "    t2_banded_metrics = {}\n",
    "    for band in std_bands:\n",
    "        t2_banded_metrics[f\"{band['range']} pixels\"] = []\n",
    "        t2_banded_metrics[f\"{band['range']} clusters\"] = []\n",
    "        \n",
    "    for sample in data:\n",
    "        x = torch.Tensor(sample).reshape((1,) + sample.shape).cuda()\n",
    "        pred = model(x)\n",
    "        \n",
    "        t1_losses.append(float(criterion(x[0][0], pred[0][0]).cpu()))\n",
    "        t2_losses.append(float(criterion(x[0][1], pred[0][1]).cpu()))\n",
    "        \n",
    "        t1_og = sample[0]\n",
    "        t2_og = sample[1]\n",
    "        pred = pred.reshape(sample.shape).detach().cpu().numpy()\n",
    "        t1_pred = pred[0]\n",
    "        t2_pred = pred[1]\n",
    "        \n",
    "        \n",
    "        t1_diff = t1_og - t1_pred\n",
    "        t1_diff_norm = t1_diff / 0.1\n",
    "        \n",
    "        t2_diff = t2_og - t2_pred\n",
    "        t2_diff_norm = t2_diff / 0.1\n",
    "        \n",
    "        t1_clusters.append(calculate_clusters(t1_diff_norm))\n",
    "        t2_clusters.append(calculate_clusters(t2_diff_norm))\n",
    "        \n",
    "        for band in std_bands:\n",
    "            filter_mask = (t1_diff_norm > band[\"low\"]) & (t1_diff_norm < band[\"high\"])\n",
    "            banded_diff = t1_diff_norm.copy()\n",
    "            banded_diff[np.invert(filter_mask)] = 0\n",
    "            banded_diff[banded_diff != 0] = 1\n",
    "            banded_diff = banded_diff.astype('uint8')\n",
    "            \n",
    "            t1_banded_metrics[f\"{band['range']} pixels\"].append(np.sum(banded_diff))\n",
    "            \n",
    "            sizes = []\n",
    "            for idx in range(0, 256):\n",
    "                cc = connected_components_2d(banded_diff[:,:,idx])\n",
    "                values, counts = np.unique(cc, return_counts=True)\n",
    "                sizes.extend(counts[1:])\n",
    "            t1_banded_metrics[f\"{band['range']} clusters\"].append(sizes)\n",
    "            \n",
    "        for band in std_bands:\n",
    "            filter_mask = (t2_diff_norm > band[\"low\"]) & (t2_diff_norm < band[\"high\"])\n",
    "            banded_diff = t2_diff_norm.copy()\n",
    "            banded_diff[np.invert(filter_mask)] = 0\n",
    "            banded_diff[banded_diff != 0] = 1\n",
    "            banded_diff = banded_diff.astype('uint8')\n",
    "            \n",
    "            t2_banded_metrics[f\"{band['range']} pixels\"].append(np.sum(banded_diff))\n",
    "            \n",
    "            sizes = []\n",
    "            for idx in range(0, 256):\n",
    "                cc = connected_components_2d(banded_diff[:,:,idx])\n",
    "                values, counts = np.unique(cc, return_counts=True)\n",
    "                sizes.extend(counts[1:])\n",
    "            t2_banded_metrics[f\"{band['range']} clusters\"].append(sizes)\n",
    "    return t1_losses, t2_losses, t1_clusters, t2_clusters, t1_banded_metrics, t2_banded_metrics\n",
    "\n",
    "\n",
    "def save_multimodal_values(t1_loss, t2_loss, t1_cluster, t2_cluster, t1_bands, t2_bands, name):\n",
    "    np.save(os.path.join(mmmetrics_dir, f\"{name}_t1_losses.npy\"), t1_loss)\n",
    "    np.save(os.path.join(mmmetrics_dir, f\"{name}_t2_losses.npy\"), t2_loss)\n",
    "    \n",
    "    np.save(os.path.join(mmmetrics_dir, f\"{name}_t1_clusters.npy\"), t1_cluster)\n",
    "    np.save(os.path.join(mmmetrics_dir, f\"{name}_t2_clusters.npy\"), t2_cluster)\n",
    "    \n",
    "    with open(os.path.join(mmmetrics_dir, f\"{name}_t1_banded_metrics.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(t1_bands,f)\n",
    "    with open(os.path.join(mmmetrics_dir, f\"{name}_t2_banded_metrics.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(t2_bands,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "47024972-52a8-47b3-bba9-20ae5605b244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1_t2\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\compute\\envs\\torch\\lib\\site-packages\\numpy\\lib\\npyio.py:501: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "model_harness = [\n",
    "    {\n",
    "        \"info\": \"t1_t2\",\n",
    "        \"model_name\": \"vae_rel2_t1_t2_second_session.pt\",\n",
    "        \"t1_only\": False,\n",
    "        \"t2_only\": False,\n",
    "        \"model\": VAE(2)\n",
    "    }\n",
    "]\n",
    "\n",
    "for model_info in model_harness:\n",
    "    print(model_info[\"info\"])\n",
    "    # Define data\n",
    "    train = Data3D(l1_dir, train_indices, t1_only=model_info[\"t1_only\"], t2_only=model_info[\"t2_only\"])\n",
    "    val = Data3D(l1_dir, val_indices, t1_only=model_info[\"t1_only\"], t2_only=model_info[\"t2_only\"])\n",
    "    test = Data3D(l5_dir, test_indices, t1_only=model_info[\"t1_only\"], t2_only=model_info[\"t2_only\"])\n",
    "\n",
    "    # Define model\n",
    "    model = model_info[\"model\"]\n",
    "    model_path = os.path.join(model_dir, model_info[\"model_name\"])\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"train\")\n",
    "    train_t1_losses, train_t2_losses, train_t1_clusters, train_t2_clusters, train_t1_banded_metrics, train_t2_banded_metrics = get_multimodal_metrics(model, train)\n",
    "    save_multimodal_values(train_t1_losses, train_t2_losses, train_t1_clusters, train_t2_clusters, train_t1_banded_metrics, train_t2_banded_metrics, \"multimodal_train\")\n",
    "    \n",
    "    print(\"val\")\n",
    "    val_t1_losses, val_t2_losses, val_t1_clusters, val_t2_clusters, val_t1_banded_metrics, val_t2_banded_metrics = get_multimodal_metrics(model, val)\n",
    "    save_multimodal_values(val_t1_losses, val_t2_losses, val_t1_clusters, val_t2_clusters, val_t1_banded_metrics, val_t2_banded_metrics, \"multimodal_val\")\n",
    "    \n",
    "    print(\"test\")\n",
    "    test_t1_losses, test_t2_losses, test_t1_clusters, test_t2_clusters, test_t1_banded_metrics, test_t2_banded_metrics = get_multimodal_metrics(model, test)\n",
    "    save_multimodal_values(test_t1_losses, test_t2_losses, test_t1_clusters, test_t2_clusters, test_t1_banded_metrics, test_t2_banded_metrics, \"multimodal_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772136c8-cf6f-44ab-8c27-ab9f866dd9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
