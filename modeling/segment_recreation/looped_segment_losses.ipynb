{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06460ebe-33ec-419b-a58a-2a13230ed9c4",
   "metadata": {},
   "source": [
    "### Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65bab4f2-d172-4fb9-be2a-4387a4c96d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\compute\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.distributions as dist\n",
    "from torchsummary import summary\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import re\n",
    "from skimage.metrics  import structural_similarity as ssim\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "# locals\n",
    "import model_architectures\n",
    "import visualization\n",
    "import unet\n",
    "\n",
    "reload(model_architectures)\n",
    "from model_architectures import VAESegment, Data3DSingleSegT2, SegMaskData\n",
    "\n",
    "reload(unet)\n",
    "from unet import UNet\n",
    "\n",
    "reload(visualization)\n",
    "from visualization import brain_diff, viz_slices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e72d957-b3f1-4218-9d45-9c49ce724f62",
   "metadata": {},
   "source": [
    "### Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52b3fae1-b241-4cbf-a8bc-233c88c6c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_dir = r\"D:/school/research\"\n",
    "code_dir = os.path.join(research_dir, \"code\")\n",
    "model_dir = os.path.join(code_dir, \"explore_again\", \"models\")\n",
    "data_dir = os.path.join(research_dir, \"data\")\n",
    "dhcp_rel2 = os.path.join(data_dir, \"dhcp_rel2\")\n",
    "processed_dir = os.path.join(dhcp_rel2, \"processed\")\n",
    "volume_dir = os.path.join(processed_dir, \"volumes\")\n",
    "seg_dir = os.path.join(processed_dir, \"segments\")\n",
    "seg_vol_dir = os.path.join(processed_dir, \"volume_segments\")\n",
    "pred_dir = os.path.join(dhcp_rel2, \"predictions\")\n",
    "seg_pred_dir = os.path.join(pred_dir, \"vae_9seg\")\n",
    "\n",
    "l1_dir = os.path.join(volume_dir, \"l1\")\n",
    "l5_dir = os.path.join(volume_dir, \"l5\")\n",
    "\n",
    "l1_seg_dir = os.path.join(seg_dir, \"l1\")\n",
    "l5_seg_dir = os.path.join(seg_dir, \"l5\")\n",
    "\n",
    "l1_seg_vol_dir = os.path.join(seg_vol_dir, \"l1\")\n",
    "l5_seg_vol_dir = os.path.join(seg_vol_dir, \"l5\")\n",
    "\n",
    "l1_seg_pred_dir = os.path.join(seg_pred_dir, \"l1\")\n",
    "l5_seg_pred_dir = os.path.join(seg_pred_dir, \"l5\")\n",
    "\n",
    "metrics_dir = os.path.join(code_dir, \"explore_again\", \"metrics\", \"individual_segments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7958dda-f8e3-458b-9b26-246036c90e20",
   "metadata": {},
   "source": [
    "### Define Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "187238df-dce1-478b-9c7f-4384b1606707",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "num_samples = int(len(os.listdir(l1_dir)) / 2)\n",
    "samples = np.array([i for i in range(0, num_samples)])\n",
    "np.random.shuffle(samples)\n",
    "\n",
    "split_val = int(0.8 * num_samples)\n",
    "train_indices = samples[0:split_val]\n",
    "val_indices = samples[split_val:]\n",
    "\n",
    "num_test = int(len(os.listdir(l5_dir)) / 2)\n",
    "test_indices = np.array([i for i in range(0, num_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea5fc4-c054-40e8-92d4-91816b2b858f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Assess Model for Each Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cd9f83e-8d50-49a6-9e09-fec5097e4592",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = [\n",
    "    \"Cerebrospinal Fluid\",\n",
    "    \"Cortical Grey Matter\",\n",
    "    \"White Matter\",\n",
    "    \"Background\",\n",
    "    \"Ventricle\",\n",
    "    \"Cerebelum\",\n",
    "    \"Deep Grey Matter\",\n",
    "    \"Brainstem\",\n",
    "    \"Hippocampus\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e4bb03b-034d-4de1-836c-f5db608b400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_losses(data, batch, segment):\n",
    "    seg_losses = []\n",
    "    for idx, img in enumerate(data):\n",
    "        x = torch.Tensor(np.reshape(img[0], (1, 1, 256, 256, 256))).cuda()\n",
    "        output = model(x)\n",
    "        pred = np.reshape(output.cpu().detach().numpy(), (1, 256, 256, 256))\n",
    "        seg_losses.append(((img[1] - pred)**2).mean())\n",
    "    \n",
    "    loss_path = os.path.join(metrics_dir, f\"vae_rel2t2_seg{segment}_{batch}_metrics.npy\")\n",
    "    np.save(loss_path, np.array(seg_losses))\n",
    "    \n",
    "    return seg_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0e4078e-c296-46d8-864e-98803029c2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model for segment 0\n",
      "Train model for segment 1\n",
      "Train model for segment 2\n",
      "Train model for segment 3\n",
      "Train model for segment 4\n",
      "Train model for segment 5\n",
      "Train model for segment 6\n",
      "Train model for segment 7\n",
      "Train model for segment 8\n",
      "CPU times: total: 18min 43s\n",
      "Wall time: 25min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for segment_number in range(0, len(segments)):\n",
    "    print(f\"Train model for segment {segment_number}\")\n",
    "    \n",
    "    # Load data for segment\n",
    "    train = Data3DSingleSegT2(l1_dir, l1_seg_vol_dir, train_indices, segment=segment_number)\n",
    "    val = Data3DSingleSegT2(l1_dir, l1_seg_vol_dir, val_indices, segment=segment_number)\n",
    "    test = Data3DSingleSegT2(l5_dir, l5_seg_vol_dir, test_indices, segment=segment_number)\n",
    "    \n",
    "    # Define output paths now :)\n",
    "    model_path = os.path.join(model_dir, f\"vae_rel2t2_seg{segment_number}.pt\")\n",
    "    model = VAESegment(1, 1)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    seg_losses1 = get_losses(train, \"train\", segment_number)\n",
    "    seg_losses2 = get_losses(val, \"val\", segment_number)\n",
    "    seg_losses3 = get_losses(test, \"test\", segment_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7567d7c-d83d-4daa-b431-68c868a5fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single segment models\n",
    "segment_label = []\n",
    "run_name = []\n",
    "values = []\n",
    "\n",
    "for segment_number in range(0, len(segments)):\n",
    "    for batch in [\"train\", \"val\", \"test\"]:\n",
    "        losses = np.load(os.path.join(metrics_dir, f\"vae_rel2t2_seg{segment_number}_{batch}_metrics.npy\"))\n",
    "        segment_label.extend([f\"{segments[segment_number]} (Single)\" for x in range(0, len(losses))])\n",
    "        run_name.extend([batch.capitalize() for x in range(0, len(losses))])\n",
    "        values.extend(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e78044a5-25af-46f6-b42e-fa700037551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All In One Model\n",
    "\n",
    "aio_metrics_dir = os.path.join(code_dir, \"explore_again\", \"metrics\", \"combined_segments\")\n",
    "\n",
    "train_seg_losses = np.load(os.path.join(aio_metrics_dir, \"train_seg_losses.npy\"))\n",
    "val_seg_losses = np.load(os.path.join(aio_metrics_dir, \"val_seg_losses.npy\"))\n",
    "test_seg_losses = np.load(os.path.join(aio_metrics_dir, \"test_seg_losses.npy\"))\n",
    "\n",
    "def get_values(list_o_vals, run_name):\n",
    "    s = []\n",
    "    v = []\n",
    "    r = []\n",
    "    for m in list_o_vals:\n",
    "        for idx, n in enumerate(m):\n",
    "            s.append(f\"{segments[idx]} (AIO)\")\n",
    "            v.append(n)\n",
    "            r.append(run_name)\n",
    "    return s, v, r\n",
    "\n",
    "train_labels, train_values, train_runs = get_values(train_seg_losses, \"Train\")\n",
    "val_labels, val_values, val_runs = get_values(val_seg_losses, \"Val\")\n",
    "test_labels, test_values, test_runs = get_values(test_seg_losses, \"Test\")\n",
    "\n",
    "values.extend(train_values)\n",
    "run_name.extend(train_runs)\n",
    "segment_label.extend(train_labels)\n",
    "\n",
    "values.extend(val_values)\n",
    "run_name.extend(val_runs)\n",
    "segment_label.extend(val_labels)\n",
    "\n",
    "values.extend(test_values)\n",
    "run_name.extend(test_runs)\n",
    "segment_label.extend(test_labels)\n",
    "\n",
    "segment_df = pd.DataFrame({\"run\": run_name, \"segment\": segment_label, \"values\": values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c29483a8-c765-4e0a-b676-ee7c3b16dd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Background (AIO)', 'Background (Single)', 'Brainstem (AIO)',\n",
       "       'Brainstem (Single)', 'Cerebelum (AIO)', 'Cerebelum (Single)',\n",
       "       'Cerebrospinal Fluid (AIO)', 'Cerebrospinal Fluid (Single)',\n",
       "       'Cortical Grey Matter (AIO)', 'Cortical Grey Matter (Single)',\n",
       "       'Deep Grey Matter (AIO)', 'Deep Grey Matter (Single)',\n",
       "       'Hippocampus (AIO)', 'Hippocampus (Single)', 'Ventricle (AIO)',\n",
       "       'Ventricle (Single)', 'White Matter (AIO)',\n",
       "       'White Matter (Single)'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0112afa-6a2f-4404-9f22-d6d8b1b01d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_26.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "segment_df.sort_values(by=['segment'])\n",
    "\n",
    "fig = px.box(\n",
    "    segment_df,\n",
    "    x=\"segment\",\n",
    "    y=\"values\",\n",
    "    # facet_col= \"marker\",\n",
    "    color=\"run\",\n",
    "    color_discrete_map={\n",
    "        \"Train\": \"green\",\n",
    "        \"Val\": \"orange\",\n",
    "        \"Test\": \"red\"\n",
    "    },\n",
    "    category_orders={\n",
    "        \"segment\": np.unique(segment_df[\"segment\"])\n",
    "    }\n",
    ")\n",
    "fig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63294fd8-1963-4f36-9348-09df74c7ba08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
