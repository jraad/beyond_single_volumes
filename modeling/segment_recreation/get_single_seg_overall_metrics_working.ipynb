{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58329eba-5543-4ed3-ab18-6649efa4299b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\compute\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.distributions as dist\n",
    "from torchsummary import summary\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import re\n",
    "from skimage.metrics  import structural_similarity as ssim\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "from importlib import reload\n",
    "import visualization\n",
    "\n",
    "# locals\n",
    "import model_architectures\n",
    "\n",
    "reload(model_architectures)\n",
    "from model_architectures import VAESegment, Data3DSegToSeg, SegMaskData, Data3DSingleSegToSingleSeg, Data3DSegToSegT1, Data3DSingleSegToSingleSegT1\n",
    "\n",
    "reload(visualization)\n",
    "from visualization import brain_diff, viz_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82115229-1959-481b-9589-aec744950784",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_dir = r\"D:/school/research\"\n",
    "code_dir = os.path.join(research_dir, \"code\")\n",
    "p2_dir = os.path.join(code_dir, \"paper_two_code\")\n",
    "model_dir = os.path.join(p2_dir, \"models\")\n",
    "data_dir = os.path.join(research_dir, \"data\")\n",
    "dhcp_rel2 = os.path.join(data_dir, \"dhcp_rel2\")\n",
    "processed_dir = os.path.join(dhcp_rel2, \"processed\")\n",
    "volume_dir = os.path.join(processed_dir, \"volumes\")\n",
    "seg_dir = os.path.join(processed_dir, \"segments\")\n",
    "seg_vol_dir = os.path.join(processed_dir, \"volume_segments\")\n",
    "pred_dir = os.path.join(dhcp_rel2, \"predictions\")\n",
    "seg_pred_dir = os.path.join(pred_dir, \"vae_9seg\")\n",
    "metrics_dir = os.path.join(p2_dir, \"metrics\")\n",
    "seg_metrics_dir = os.path.join(metrics_dir, \"seg_to_seg\")\n",
    "\n",
    "l1_dir = os.path.join(volume_dir, \"l1\")\n",
    "l5_dir = os.path.join(volume_dir, \"l5\")\n",
    "\n",
    "l1_seg_dir = os.path.join(seg_dir, \"l1\")\n",
    "l5_seg_dir = os.path.join(seg_dir, \"l5\")\n",
    "\n",
    "l1_seg_vol_dir = os.path.join(seg_vol_dir, \"l1\")\n",
    "l5_seg_vol_dir = os.path.join(seg_vol_dir, \"l5\")\n",
    "\n",
    "l1_seg_pred_dir = os.path.join(seg_pred_dir, \"l1\")\n",
    "l5_seg_pred_dir = os.path.join(seg_pred_dir, \"l5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5fd039b-5e59-41e3-921c-07b4d4504f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = [\n",
    "    \"Cerebrospinal Fluid\",\n",
    "    \"Cortical Grey Matter\",\n",
    "    \"White Matter\",\n",
    "    \"Background\",\n",
    "    \"Ventricle\",\n",
    "    \"Cerebelum\",\n",
    "    \"Deep Grey Matter\",\n",
    "    \"Brainstem\",\n",
    "    \"Hippocampus\"\n",
    "]\n",
    "\n",
    "std_bands = [\n",
    "    {\n",
    "        \"range\": \"-inf to -4\",\n",
    "        \"low\": -np.inf,\n",
    "        \"high\": -4\n",
    "    },\n",
    "    {\n",
    "        \"range\": \"-4 to -3\",\n",
    "        \"low\": -4,\n",
    "        \"high\": -3\n",
    "    },\n",
    "    {\n",
    "        \"range\": \"-3 to -2\",\n",
    "        \"low\": -3,\n",
    "        \"high\": -2\n",
    "    },\n",
    "    {\n",
    "        \"range\": \"2 to 3\",\n",
    "        \"low\": 2,\n",
    "        \"high\": 3\n",
    "    },\n",
    "    {\n",
    "        \"range\": \"3 to 4\",\n",
    "        \"low\": 3,\n",
    "        \"high\": 4\n",
    "    },\n",
    "    {\n",
    "        \"range\": \"4 to inf\",\n",
    "        \"low\": 4,\n",
    "        \"high\": np.inf\n",
    "    }\n",
    "]\n",
    "\n",
    "def connected_components_2d(diff):\n",
    "    _, labels = cv2.connectedComponents(diff)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "def calculate_clusters(diff, threshold=2):\n",
    "    cluster_diff = diff.copy()\n",
    "    filter_mask = (diff > -threshold) & (diff < threshold)\n",
    "    cluster_diff[filter_mask] = 0\n",
    "    cluster_diff[cluster_diff != 0] = 1\n",
    "    prepared_diff = cluster_diff.astype('uint8')\n",
    "    sizes = []\n",
    "    \n",
    "    for idx in range(0, 256):\n",
    "        clusters = connected_components_2d(prepared_diff[:,:,idx])\n",
    "        values, counts = np.unique(clusters, return_counts=True)\n",
    "        sizes.extend(counts[1:])\n",
    "        \n",
    "    return sizes\n",
    "\n",
    "\n",
    "def get_overall_metrics(model, data):\n",
    "    criterion = nn.MSELoss()\n",
    "    losses = []\n",
    "    segment_losses = {s: [] for s in segments}\n",
    "    clusters = []\n",
    "    segment_clusters = {s: [] for s in segments}\n",
    "    banded_metrics = {}\n",
    "    for band in std_bands:\n",
    "        banded_metrics[f\"{band['range']} pixels\"] = []\n",
    "        banded_metrics[f\"{band['range']} clusters\"] = []\n",
    "    \n",
    "    banded_segment_metrics = {}\n",
    "    for band in std_bands:\n",
    "        banded_segment_metrics[f\"{band['range']} pixels\"] = {s: [] for s in segments}\n",
    "        banded_segment_metrics[f\"{band['range']} clusters\"] = {s: [] for s in segments}\n",
    "        \n",
    "    counter = 0\n",
    "    for sample in data:\n",
    "        x = torch.Tensor(sample).reshape((1,) + sample.shape).cuda()\n",
    "        pred = model(x)\n",
    "        \n",
    "        losses.append(float(criterion(x, pred).cpu()))\n",
    "        \n",
    "        for idx, segment in enumerate(segments):\n",
    "            segment_losses[segment].append(float(criterion(x[:,idx,:,:,:], pred[:,idx,:,:,:]).cpu()))\n",
    "        \n",
    "        # Get overall cluster data\n",
    "        og = sample\n",
    "        pred = pred.reshape(og.shape).detach().cpu().numpy()\n",
    "        \n",
    "        diff = np.sum(og, axis=0) - np.sum(pred, axis=0)\n",
    "        diff_norm = diff / 0.1\n",
    "        \n",
    "        clusters.append(np.mean(calculate_clusters(diff_norm)))\n",
    "        \n",
    "        # Get segmented cluster data\n",
    "        for idx, segment in enumerate(segments):\n",
    "            diff = og[idx,:,:,:] - pred[idx,:,:,:]\n",
    "            diff_norm = diff / 0.1\n",
    "            segment_clusters[segment].append(np.mean(calculate_clusters(diff_norm)))\n",
    "        \n",
    "        # For overall banded metrics\n",
    "        for band in std_bands:\n",
    "            diff = np.sum(og, axis=0) - np.sum(pred, axis=0)\n",
    "            diff_norm = diff / 0.1\n",
    "            filter_mask = (diff_norm > band[\"low\"]) & (diff_norm < band[\"high\"])\n",
    "            banded_diff = diff_norm.copy()\n",
    "            banded_diff[np.invert(filter_mask)] = 0\n",
    "            banded_diff[banded_diff != 0] = 1\n",
    "            banded_diff = banded_diff.astype('uint8')\n",
    "            \n",
    "            banded_metrics[f\"{band['range']} pixels\"].append(np.sum(banded_diff))\n",
    "            \n",
    "            sizes = []\n",
    "            for idx in range(0, 256):\n",
    "                cc = connected_components_2d(banded_diff[:,:,idx])\n",
    "                values, counts = np.unique(cc, return_counts=True)\n",
    "                sizes.extend(counts[1:])\n",
    "            banded_metrics[f\"{band['range']} clusters\"].append(np.mean(sizes))\n",
    "        \n",
    "        # For segmented banded metrics\n",
    "        for band in std_bands:\n",
    "            for idx, segment in enumerate(segments):\n",
    "                diff = og[idx,:,:,:] - pred[idx,:,:,:]\n",
    "                diff_norm = diff / 0.1\n",
    "                \n",
    "                filter_mask = (diff_norm > band[\"low\"]) & (diff_norm < band[\"high\"])\n",
    "                banded_diff = diff_norm.copy()\n",
    "                banded_diff[np.invert(filter_mask)] = 0\n",
    "                banded_diff[banded_diff != 0] = 1\n",
    "                banded_diff = banded_diff.astype('uint8')\n",
    "                \n",
    "                banded_segment_metrics[f\"{band['range']} pixels\"][segment].append(np.sum(banded_diff))\n",
    "                \n",
    "                sizes = []\n",
    "                for idx in range(0, 256):\n",
    "                    cc = connected_components_2d(banded_diff[:,:,idx])\n",
    "                    values, counts = np.unique(cc, return_counts=True)\n",
    "                    sizes.extend(counts[1:])\n",
    "                if len(sizes) == 0:\n",
    "                    banded_segment_metrics[f\"{band['range']} clusters\"][segment].append(0)\n",
    "                else:\n",
    "                    banded_segment_metrics[f\"{band['range']} clusters\"][segment].append(np.mean(sizes))\n",
    "\n",
    "    return losses, segment_losses, clusters, segment_clusters, banded_metrics, banded_segment_metrics\n",
    "\n",
    "\n",
    "def save_values(losses, segment_losses, clusters, segment_clusters, banded_metrics, banded_segment_metrics, name, run):\n",
    "    prefix = f\"{name}_{run}\"\n",
    "    np.save(os.path.join(seg_metrics_dir, f\"{prefix}_losses.npy\"), losses)\n",
    "    np.save(os.path.join(seg_metrics_dir, f\"{prefix}_segment_losses.npy\"), segment_losses)\n",
    "    np.save(os.path.join(seg_metrics_dir, f\"{prefix}_clusters.npy\"), clusters)\n",
    "    np.save(os.path.join(seg_metrics_dir, f\"{prefix}_segment_clusters.npy\"), segment_clusters)\n",
    "    with open(os.path.join(seg_metrics_dir, f\"{prefix}_banded_metrics.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(banded_metrics,f)\n",
    "    with open(os.path.join(seg_metrics_dir, f\"{prefix}_banded_segment_metrics.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(banded_segment_metrics,f)\n",
    "\n",
    "\n",
    "def get_single_seg_metrics(model, data):\n",
    "    criterion = nn.MSELoss()\n",
    "    losses = []\n",
    "    clusters = []\n",
    "    banded_metrics = {}\n",
    "    for band in std_bands:\n",
    "        banded_metrics[f\"{band['range']} pixels\"] = []\n",
    "        banded_metrics[f\"{band['range']} clusters\"] = []\n",
    "\n",
    "    for sample in data:\n",
    "        x = torch.Tensor(sample).reshape((1,) + sample.shape).cuda()\n",
    "        pred = model(x)\n",
    "        \n",
    "        losses.append(float(criterion(x, pred).cpu()))\n",
    "        \n",
    "        og = sample\n",
    "        pred = pred.reshape(og.shape).detach().cpu().numpy()\n",
    "        \n",
    "        diff = np.sum(og, axis=0) - np.sum(pred, axis=0)\n",
    "        diff_norm = diff / 0.1\n",
    "        \n",
    "        clusters.append(np.mean(calculate_clusters(diff_norm)))\n",
    "        \n",
    "        for band in std_bands:\n",
    "            filter_mask = (diff_norm > band[\"low\"]) & (diff_norm < band[\"high\"])\n",
    "            banded_diff = diff_norm.copy()\n",
    "            banded_diff[np.invert(filter_mask)] = 0\n",
    "            banded_diff[banded_diff != 0] = 1\n",
    "            banded_diff = banded_diff.astype('uint8')\n",
    "            \n",
    "            banded_metrics[f\"{band['range']} pixels\"].append(np.sum(banded_diff))\n",
    "            \n",
    "            sizes = []\n",
    "            for idx in range(0, 256):\n",
    "                cc = connected_components_2d(banded_diff[:,:,idx])\n",
    "                values, counts = np.unique(cc, return_counts=True)\n",
    "                sizes.extend(counts[1:])\n",
    "            banded_metrics[f\"{band['range']} clusters\"].append(np.mean(sizes))\n",
    "\n",
    "    return losses, clusters, banded_metrics\n",
    "\n",
    "def save_values(losses, segment_losses, clusters, segment_clusters, banded_metrics, banded_segment_metrics, name, run):\n",
    "    prefix = f\"{name}_{run}\"\n",
    "    np.save(os.path.join(seg_metrics_dir, f\"{prefix}_losses.npy\"), losses)\n",
    "    np.save(os.path.join(seg_metrics_dir, f\"{prefix}_segment_losses.npy\"), segment_losses)\n",
    "    np.save(os.path.join(seg_metrics_dir, f\"{prefix}_clusters.npy\"), clusters)\n",
    "    np.save(os.path.join(seg_metrics_dir, f\"{prefix}_segment_clusters.npy\"), segment_clusters)\n",
    "    with open(os.path.join(seg_metrics_dir, f\"{prefix}_banded_metrics.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(banded_metrics,f)\n",
    "    with open(os.path.join(seg_metrics_dir, f\"{prefix}_banded_segment_metrics.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(banded_segment_metrics,f)\n",
    "\n",
    "        \n",
    "def save_seg_values(losses, clusters, banded_metrics, name, run):\n",
    "    prefix = f\"{name}_{run}\"\n",
    "    np.save(os.path.join(seg_metrics_dir, f\"{prefix}_losses.npy\"), losses)\n",
    "    np.save(os.path.join(seg_metrics_dir, f\"{prefix}_clusters.npy\"), clusters)\n",
    "    with open(os.path.join(seg_metrics_dir, f\"{prefix}_banded_metrics.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(banded_metrics,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ed7697d-95a1-466f-ac45-fb1c25eb0e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "num_samples = int(len(os.listdir(l1_dir)) / 2)\n",
    "samples = np.array([i for i in range(0, num_samples)])\n",
    "np.random.shuffle(samples)\n",
    "\n",
    "split_val = int(0.8 * num_samples)\n",
    "train_indices = samples[0:split_val]\n",
    "val_indices = samples[split_val:]\n",
    "\n",
    "num_test = int(len(os.listdir(l5_dir)) / 2)\n",
    "test_indices = np.array([i for i in range(0, num_test)])\n",
    "\n",
    "train = Data3DSegToSeg(l1_dir, l1_seg_vol_dir, train_indices)\n",
    "val = Data3DSegToSeg(l1_dir, l1_seg_vol_dir, val_indices)\n",
    "test = Data3DSegToSeg(l5_dir, l5_seg_vol_dir, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "805ad305-cffd-49e4-abcd-fb3889ffb8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = \"vae_rel2t2_seg_to_seg\"\n",
    "criterion = nn.MSELoss()\n",
    "losses = []\n",
    "clusters = []\n",
    "banded_metrics = {}\n",
    "for band in std_bands:\n",
    "    banded_metrics[f\"{band['range']} pixels\"] = []\n",
    "    banded_metrics[f\"{band['range']} clusters\"] = []\n",
    "\n",
    "for sample in train:\n",
    "    pred_img = np.empty_like(sample)\n",
    "    for segment_number in range(0, len(segments)):\n",
    "        model_path = os.path.join(model_dir, f\"{base_model_name}{segment_number}.pt\")\n",
    "        model = VAESegment(1, 1)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.cuda()\n",
    "        model.eval()\n",
    "\n",
    "        x = torch.Tensor(sample[segment_number]).reshape((1, 1, 256, 256, 256)).cuda()\n",
    "        pred = model(x)\n",
    "        pred_img[segment_number] = pred.reshape((256, 256, 256)).detach().cpu().numpy()\n",
    "    \n",
    "    losses.append(float(criterion(torch.Tensor(sample), torch.Tensor(pred_img))))\n",
    "    \n",
    "    diff = np.sum(sample, axis=0) - np.sum(pred_img, axis=0)\n",
    "    diff_norm = diff / 0.1\n",
    "    \n",
    "    clusters.append(np.mean(calculate_clusters(diff_norm)))\n",
    "    \n",
    "    # For overall banded metrics\n",
    "    for band in std_bands:\n",
    "        diff = np.sum(sample, axis=0) - np.sum(pred_img, axis=0)\n",
    "        diff_norm = diff / 0.1\n",
    "        filter_mask = (diff_norm > band[\"low\"]) & (diff_norm < band[\"high\"])\n",
    "        banded_diff = diff_norm.copy()\n",
    "        banded_diff[np.invert(filter_mask)] = 0\n",
    "        banded_diff[banded_diff != 0] = 1\n",
    "        banded_diff = banded_diff.astype('uint8')\n",
    "\n",
    "        banded_metrics[f\"{band['range']} pixels\"].append(np.sum(banded_diff))\n",
    "\n",
    "        sizes = []\n",
    "        for idx in range(0, 256):\n",
    "            cc = connected_components_2d(banded_diff[:,:,idx])\n",
    "            values, counts = np.unique(cc, return_counts=True)\n",
    "            sizes.extend(counts[1:])\n",
    "        banded_metrics[f\"{band['range']} clusters\"].append(np.mean(sizes))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb94f966-d9ac-4cd8-940f-b2752a6c5933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.001519416575320065],\n",
       " [19.46075384143939],\n",
       " {'-inf to -4 pixels': [10521],\n",
       "  '-inf to -4 clusters': [7.563623292595255],\n",
       "  '-4 to -3 pixels': [52021],\n",
       "  '-4 to -3 clusters': [8.438118410381184],\n",
       "  '-3 to -2 pixels': [242948],\n",
       "  '-3 to -2 clusters': [13.180772569444445],\n",
       "  '2 to 3 pixels': [85786],\n",
       "  '2 to 3 clusters': [5.190343659244918],\n",
       "  '3 to 4 pixels': [38731],\n",
       "  '3 to 4 clusters': [5.11840888066605],\n",
       "  '4 to inf pixels': [14534],\n",
       "  '4 to inf clusters': [6.338421282163105]})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_overall_metrics_single_seg(\"vae_rel2t2_seg_to_seg\", train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2344571-d55c-4f7f-91fb-50d325892193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-inf to -4 pixels': [10521],\n",
       " '-inf to -4 clusters': [7.563623292595255],\n",
       " '-4 to -3 pixels': [52021],\n",
       " '-4 to -3 clusters': [8.438118410381184],\n",
       " '-3 to -2 pixels': [242948],\n",
       " '-3 to -2 clusters': [13.180772569444445],\n",
       " '2 to 3 pixels': [85786],\n",
       " '2 to 3 clusters': [5.190343659244918],\n",
       " '3 to 4 pixels': [38731],\n",
       " '3 to 4 clusters': [5.11840888066605],\n",
       " '4 to inf pixels': [14534],\n",
       " '4 to inf clusters': [6.338421282163105]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_overall_metrics_single_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5ba1ff0-ab02-43aa-972b-7df3943d3206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overall_metrics_single_seg(base_model_name, data):\n",
    "    criterion = nn.MSELoss()\n",
    "    losses = []\n",
    "    clusters = []\n",
    "    banded_metrics = {}\n",
    "    for band in std_bands:\n",
    "        banded_metrics[f\"{band['range']} pixels\"] = []\n",
    "        banded_metrics[f\"{band['range']} clusters\"] = []\n",
    "        \n",
    "    for sample in data:\n",
    "        pred_img = np.empty_like(sample)\n",
    "        for segment_number in range(0, len(segments)):\n",
    "            model_path = os.path.join(model_dir, f\"{base_model_name}{segment_number}.pt\")\n",
    "            model = VAESegment(1, 1)\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            model.cuda()\n",
    "            model.eval()\n",
    "\n",
    "            x = torch.Tensor(sample[segment_number]).reshape((1, 1, 256, 256, 256)).cuda()\n",
    "            pred = model(x)\n",
    "            pred_img[segment_number] = pred.reshape((256, 256, 256)).detach().cpu().numpy()\n",
    "\n",
    "        losses.append(float(criterion(torch.Tensor(sample), torch.Tensor(pred_img))))\n",
    "\n",
    "        diff = np.sum(sample, axis=0) - np.sum(pred_img, axis=0)\n",
    "        diff_norm = diff / 0.1\n",
    "\n",
    "        clusters.append(np.mean(calculate_clusters(diff_norm)))\n",
    "\n",
    "        # For overall banded metrics\n",
    "        for band in std_bands:\n",
    "            diff = np.sum(sample, axis=0) - np.sum(pred_img, axis=0)\n",
    "            diff_norm = diff / 0.1\n",
    "            filter_mask = (diff_norm > band[\"low\"]) & (diff_norm < band[\"high\"])\n",
    "            banded_diff = diff_norm.copy()\n",
    "            banded_diff[np.invert(filter_mask)] = 0\n",
    "            banded_diff[banded_diff != 0] = 1\n",
    "            banded_diff = banded_diff.astype('uint8')\n",
    "\n",
    "            banded_metrics[f\"{band['range']} pixels\"].append(np.sum(banded_diff))\n",
    "\n",
    "            sizes = []\n",
    "            for idx in range(0, 256):\n",
    "                cc = connected_components_2d(banded_diff[:,:,idx])\n",
    "                values, counts = np.unique(cc, return_counts=True)\n",
    "                sizes.extend(counts[1:])\n",
    "            banded_metrics[f\"{band['range']} clusters\"].append(np.mean(sizes))\n",
    "        \n",
    "    return losses, clusters, banded_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7935edd-3058-4d83-a273-1d9f78bc0ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
